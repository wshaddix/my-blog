<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Wes Shaddix | Blog</title>
    <link>http://www.wesshaddix.com/</link>
    <description>Recent content on Wes Shaddix | Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 21 May 2018 09:53:37 -0400</lastBuildDate>
    
        <atom:link href="http://www.wesshaddix.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Upgrading Ubuntu on Docker Swarm Node</title>
      <link>http://www.wesshaddix.com/post/upgrading-ubuntu-on-docker-swarm-node/</link>
      <pubDate>Mon, 21 May 2018 09:53:37 -0400</pubDate>
      
      <guid>http://www.wesshaddix.com/post/upgrading-ubuntu-on-docker-swarm-node/</guid>
      
        <description>&lt;p&gt;In this post I&amp;rsquo;m going to document the steps needed to upgrade the OS of docker swarm nodes from Ubuntu 17.10 to Ubuntu 18.04
&lt;/p&gt;

&lt;h1 id=&#34;scenario&#34;&gt;Scenario&lt;/h1&gt;

&lt;p&gt;From time to time you&amp;rsquo;ll need to update the OS of the docker swarm nodes. In my case I&amp;rsquo;m upgrading from Ubuntu 17.10 to Ubuntu 18.04. You have to be cautious of two things when your host is in a docker swarm node. First you have to drain the node that is being updated so that no services are running on the node (and thus disappear) and second you have to make sure you never lose quorum on the swarm cluster by removing a manager node. &lt;strong&gt;To maintain quorum, a majority of managers must be available.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;step-1-evaluate-manager-status&#34;&gt;Step 1: Evaluate Manager Status&lt;/h2&gt;

&lt;p&gt;The first step is to evaluate the manager status of the node. If the node is not a manager then you don&amp;rsquo;t have to worry about losing the quorum when you take the node offline. If the node is a manager, then you need to promote another node in order to take over for the node that you&amp;rsquo;re about to update.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker node promote &amp;lt;worker node name&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker node demote &amp;lt;manager node name&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;step-2-drain-the-node&#34;&gt;Step 2: Drain the Node&lt;/h2&gt;

&lt;p&gt;The next step is to drain the node so that the services currently running on that node are moved to other nodes in the swarm.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker node update --availability drain &amp;lt;node name&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;You can verify the status by running&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker node ls&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and you should see that the &lt;code&gt;AVAILABILITY&lt;/code&gt; of the node is &lt;code&gt;Drain&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;You can verify that no containers are running on the node by running&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker container ps&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;step-3-perform-the-os-upgrade&#34;&gt;Step 3: Perform the OS upgrade&lt;/h2&gt;

&lt;p&gt;From the drained node perform the OS upgrade by running&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo do-release-upgrade&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Follow the prompts and answer the questions. Eventually you&amp;rsquo;ll be prompted to restart the computer.&lt;/p&gt;

&lt;h2 id=&#34;step-4-add-the-new-docker-repository&#34;&gt;Step 4: Add the new Docker Repository&lt;/h2&gt;

&lt;p&gt;Now that you have a new Ubuntu version you need to update the docker repository so that you can pull in the latest updates for your new version of Ubuntu.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo add-apt-repository &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;   &lt;span class=&#34;s2&#34;&gt;&amp;#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;lsb_release -cs&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt; \
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;   stable&amp;#34;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;followed by&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo apt-get update&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;step-5-activate-the-node&#34;&gt;Step 5: Activate the Node&lt;/h2&gt;

&lt;p&gt;Set the node back to active in the swarm cluster by running the following command on a manager node&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker node update --availability Active &amp;lt;node name&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;You can verify the status by running&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker node ls&lt;/code&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Docker Recipies</title>
      <link>http://www.wesshaddix.com/post/docker-recipies/</link>
      <pubDate>Fri, 18 May 2018 14:38:10 -0400</pubDate>
      
      <guid>http://www.wesshaddix.com/post/docker-recipies/</guid>
      
        <description>&lt;h1 id=&#34;handy-recipies-when-working-with-docker&#34;&gt;Handy recipies when working with docker&lt;/h1&gt;

&lt;p&gt;The more you work with docker the more little tips and tricks you pick up on to make your life easier. These are some of the more useful things that I&amp;rsquo;ve learned along the way.
&lt;/p&gt;

&lt;h2 id=&#34;building-images-from-a-dockerfile&#34;&gt;Building Images from a Dockerfile&lt;/h2&gt;

&lt;h3 id=&#34;1-optimizing-the-build-context&#34;&gt;1. Optimizing the Build Context&lt;/h3&gt;

&lt;h4 id=&#34;scenario&#34;&gt;Scenario&lt;/h4&gt;

&lt;p&gt;I typically build .net core microservice images using multi-stage builds. In the first stage, where I have my SDK tools installed, I&amp;rsquo;m typically copying over the solution (.sln), project (.csproj) and nuget (nuget.config) files. After that I restore my project dependencies (nuget restore) and then I&amp;rsquo;ll copy in &lt;em&gt;everything else&lt;/em&gt; before I publish the application.&lt;/p&gt;

&lt;h4 id=&#34;problem&#34;&gt;Problem&lt;/h4&gt;

&lt;p&gt;If you don&amp;rsquo;t have a &lt;code&gt;.dockerignore&lt;/code&gt; file, then when you copy &lt;em&gt;everything else&lt;/em&gt; you&amp;rsquo;ll get a lot more than you need copied into your docker build context which is wasteful for both the image building process as well as your resulting image contents.&lt;/p&gt;

&lt;h4 id=&#34;solution&#34;&gt;Solution&lt;/h4&gt;

&lt;p&gt;After you copy in &lt;em&gt;everything else&lt;/em&gt;, but before you build/publish your code (just comment those lines out in your &lt;code&gt;Dockerfile&lt;/code&gt;) you can create a temporary container and login to view what you&amp;rsquo;ve actually copied into the build context. The easiest way I&amp;rsquo;ve found to do this is to grab the &lt;code&gt;id&lt;/code&gt; of the layer from the &lt;code&gt;docker build&lt;/code&gt; output and create a temporary container from that intermidiate layer to view the contents of the filesystem.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker run --entrypoint sh -it --rm &amp;lt;layer id&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/app # find (this will show you the files that you copied from the build context to the filesystem)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;You can use this list of files to guide you as you ignore them and the unnecessary directories in your &lt;code&gt;.dockerignore&lt;/code&gt; file. Repeat until it&amp;rsquo;s optimized with no wasted files or directories.&lt;/p&gt;

&lt;h3 id=&#34;2-net-core-dockerfile&#34;&gt;2. .Net Core .dockerfile&lt;/h3&gt;

&lt;p&gt;My typical starting point for a &lt;code&gt;.dockerignore&lt;/code&gt; file for a .net core application hosted on bitbucket is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;.dockerignore
.gitignore
bitbucket-pipelines.yml
docker-compose.yml
Dockerfile
README.md
**/*/bin*
**/*/obj*
.git
.vs&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;3-net-core-dockerfile&#34;&gt;3. .Net Core Dockerfile&lt;/h3&gt;

&lt;p&gt;My typical starting point for a &lt;code&gt;Dockerfile&lt;/code&gt; for a .net core application is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-docker&#34; data-lang=&#34;docker&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-docker&#34; data-lang=&#34;docker&#34;&gt;&lt;span class=&#34;c&#34;&gt;# STAGE 1 - COMPILE AND PUBLISH&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# use the image that has the build tools for the &amp;#34;build stage&amp;#34;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;s&#34;&gt; microsoft/dotnet:2.1-sdk-alpine AS build-env&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# set the working directory in the image as &amp;#34;app&amp;#34;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WORKDIR&lt;/span&gt;&lt;span class=&#34;s&#34;&gt; /app&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# copy the solution, project and nuget files&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;COPY &amp;lt;SOLUTION&amp;gt;.sln ./&amp;lt;SOLUTION&amp;gt;.sln&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;COPY global.json ./global.json&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;COPY ./src/&amp;lt;PROJECT&amp;gt;.csproj ./src/&amp;lt;PROJECT&amp;gt;.csproj&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;COPY ./tests/&amp;lt;TESTS&amp;gt;.csproj ./tests/&amp;lt;TEST&amp;gt;.csproj&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;COPY NuGet.config .&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# restore the nuget packages (cache this layer since it doesn&amp;#39;t change often)&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;RUN&lt;/span&gt; dotnet restore&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# copy the rest of the code&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;COPY . ./&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# publish&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;RUN&lt;/span&gt; dotnet publish -c Release -o /publish ./&amp;lt;SOLUTION&amp;gt;.sln&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# STAGE 2 - BUILD RUNTIME OPTIMIZED IMAGE&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# use the runtime optimized image that does not have any build tools, only the .net core runtime&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;s&#34;&gt; microsoft/dotnet:2.1-runtime-alpine&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# set the working directory in the image as &amp;#34;app&amp;#34;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WORKDIR&lt;/span&gt;&lt;span class=&#34;s&#34;&gt; /app&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# copy the compiled code from the published output folder of the &amp;#34;build stage&amp;#34; into this image&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;COPY --from&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;build-env /publish .&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# set the default command that will run when this image is ran&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ENTRYPOINT&lt;/span&gt;&lt;span class=&#34;s&#34;&gt; [ &amp;#34;dotnet&amp;#34;, &amp;#34;&amp;lt;PROJECT&amp;gt;.dll&amp;#34;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
      
    </item>
    
    <item>
      <title>Visualizing a Docker Swarm Cluster</title>
      <link>http://www.wesshaddix.com/post/visualizing-a-docker-swarm-cluster/</link>
      <pubDate>Sun, 31 Dec 2017 18:49:43 -0500</pubDate>
      
      <guid>http://www.wesshaddix.com/post/visualizing-a-docker-swarm-cluster/</guid>
      
        <description>

&lt;p&gt;&lt;strong&gt;[Updated] &lt;sup&gt;12&lt;/sup&gt;&amp;frasl;&lt;sub&gt;31&lt;/sub&gt; - Updated instructions to leverage the load balancer configuration that we added to the swarm cluster.&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;goal&#34;&gt;Goal&lt;/h1&gt;

&lt;p&gt;In a &lt;a href=&#34;http://www.wesshaddix.com/post/three-node-docker-swarm-cluster/&#34;&gt;previous blog post&lt;/a&gt; I setup a docker swarm cluster. Now I want a way to visualize what the swarm cluster looks like. How many nodes I have and which containers are running. Also as I change the state of the swarm cluster through docker commands I&amp;rsquo;d like to visualize what is actually happening.&lt;/p&gt;

&lt;h2 id=&#34;the-solution&#34;&gt;The solution&lt;/h2&gt;

&lt;p&gt;There is a docker image named &lt;code&gt;dockersamples/visualizer&lt;/code&gt; that will give you a url that you can go to in order to view your swarm cluster. We will run this as a service on our cluster and bind it to run on &lt;strong&gt;just the manager node&lt;/strong&gt; and not on the workers.&lt;/p&gt;

&lt;h3 id=&#34;install-the-visualizer-service&#34;&gt;Install the visualizer service&lt;/h3&gt;

&lt;p&gt;Connect to your docker swarm manager node and setup a new service using the visualizer image. We are going to expose the visualizer on port 80 which we already opened up in both the network security group and the load balancer from the previous post.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;service&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;create&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;\&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;-name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;viz&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;\&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;-publish&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tcp&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;\&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;-constraint&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;role&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;manager&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;\&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;-mount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;src&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;var&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dst&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;var&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sock&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;\&lt;/span&gt;
  &lt;span class=&#34;n&#34;&gt;dockersamples&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;visualizer&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;verify-that-it-works&#34;&gt;Verify that it works&lt;/h3&gt;

&lt;p&gt;If you navigate to &lt;a href=&#34;http://your-swarm-cluster&#34;&gt;http://your-swarm-cluster&lt;/a&gt; you will see what it looks like.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Three Node Docker Swarm with Ubuntu 17.04 on Azure</title>
      <link>http://www.wesshaddix.com/post/three-node-docker-swarm-cluster/</link>
      <pubDate>Thu, 28 Dec 2017 17:31:03 -0500</pubDate>
      
      <guid>http://www.wesshaddix.com/post/three-node-docker-swarm-cluster/</guid>
      
        <description>

&lt;p&gt;&lt;strong&gt;[Updated] &lt;sup&gt;12&lt;/sup&gt;&amp;frasl;&lt;sub&gt;28&lt;/sub&gt; - Improved the setup so that we can use a load balancer in front of the swarm nodes as well as improve the availability of the swarm nodes&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;

&lt;p&gt;I&amp;rsquo;m learning docker swarm mode and need a realistic simulation of setting up a multi-node cluster. Azure is an ideal platform to test things out. My goal is to create a docker swarm cluster within a &lt;strong&gt;single&lt;/strong&gt; region. Creating a multi-region swarm cluster requires creating virutal networks in different regions and connecting those vnets through a vpn gateway which is not something I&amp;rsquo;m ready to tackle just yet.&lt;/p&gt;

&lt;h2 id=&#34;my-setup&#34;&gt;My setup&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;m running a windows 10 workstation with docker for windows.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;λ&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ver&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;Microsoft&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Windows&lt;/span&gt; &lt;span class=&#34;no&#34;&gt;[Version 10.0.16299.125]&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;λ&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;-version&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;Docker&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;version&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;17&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;09&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;1-ce&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;build&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;19e2cf6&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;getting-the-azure-cli-v2&#34;&gt;Getting the azure cli v2&lt;/h2&gt;

&lt;p&gt;I know I want to use the Azure CLI v2 in order to be able to manage my azure resources from the command line but I don&amp;rsquo;t want to have to install/configure it along with whatever programming languages it requires. Instead I just want to use it from a docker image. In order to do that, I need to download and run it in a container so from my &lt;strong&gt;powershell&lt;/strong&gt; terminal I run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;run&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;-rm&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-v&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HOME&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;root&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-it&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;azuresdk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;azure-cli-python&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;latest&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This will run a container that has the azure cli ready to go. The &lt;code&gt;--rm&lt;/code&gt; argument means that the container will be removed once I exit from it. The &lt;code&gt;-v ${HOME}:/root&lt;/code&gt; argument maps my home directory on my Windows 10 host to the /root folder inside the docker container. This means anything written to the /root folder in the container will be saved on my host machine and be available the next time I run the container. Finally the &lt;code&gt;-it&lt;/code&gt; argument will put me at the terminal of the container where I can interact with it.&lt;/p&gt;

&lt;h2 id=&#34;logging-into-my-azure-account&#34;&gt;Logging into my azure account&lt;/h2&gt;

&lt;p&gt;Now that I have access to the Azure CLI, I need to authenticate to my Azure account. To do that I run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;az&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;login&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;When you run this command it will give you a url along with a code. Simply open the url in your web browser and paste in the code and it will authorize your Azure CLI to access your Azure account.&lt;/p&gt;

&lt;h2 id=&#34;the-script&#34;&gt;The script&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;m going to show the entire script here that you can run from the azure cli for convenience. In the rest of this post I&amp;rsquo;ll describe what each command does.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nv&#34;&gt;RESOURCE_GROUP&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;dev-docker-swarm-us-east&amp;#34;&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;VNET_NAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;vnet-docker-swarm&amp;#34;&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;SUBNET_NAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;subnet-docker-swarm&amp;#34;&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;NSG_NAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;nsg-docker-swarm&amp;#34;&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;LOAD_BALANCER_NAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;load-balancer-swarm-cluster&amp;#34;&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;OS_IMAGE&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Canonical:UbuntuServer:17.04:17.04.201711210&amp;#34;&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;VM_SIZE&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Standard_B2S&amp;#34;&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;ADMIN_USERNAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;wshaddix&amp;#34;&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;AVAILABILITY_SET_NAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;availability-set-swarm-nodes&amp;#34;&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# create a resource group
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;az group create -l eastus -n &lt;span class=&#34;nv&#34;&gt;$RESOURCE_GROUP&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# create a network security group
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;az network nsg create -g &lt;span class=&#34;nv&#34;&gt;$RESOURCE_GROUP&lt;/span&gt; -n &lt;span class=&#34;nv&#34;&gt;$NSG_NAME&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# create a virtual network
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;az network vnet create -g &lt;span class=&#34;nv&#34;&gt;$RESOURCE_GROUP&lt;/span&gt; -n &lt;span class=&#34;nv&#34;&gt;$VNET_NAME&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# create a subnet
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;az network vnet subnet create -g &lt;span class=&#34;nv&#34;&gt;$RESOURCE_GROUP&lt;/span&gt; -n &lt;span class=&#34;nv&#34;&gt;$SUBNET_NAME&lt;/span&gt; --vnet-name &lt;span class=&#34;nv&#34;&gt;$VNET_NAME&lt;/span&gt; --address-prefix &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;.0.0.0/24 --network-security-group &lt;span class=&#34;nv&#34;&gt;$NSG_NAME&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# create a public ip address for the load balancer (front-end)
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;az network public-ip create -g &lt;span class=&#34;nv&#34;&gt;$RESOURCE_GROUP&lt;/span&gt; -n &lt;span class=&#34;nv&#34;&gt;$LOAD_BALANCER_NAME&lt;/span&gt;-ip --allocation-method Static

&lt;span class=&#34;c1&#34;&gt;# create a load balancer
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;az network lb create -g &lt;span class=&#34;nv&#34;&gt;$RESOURCE_GROUP&lt;/span&gt; -n &lt;span class=&#34;nv&#34;&gt;$LOAD_BALANCER_NAME&lt;/span&gt; --public-ip-address &lt;span class=&#34;nv&#34;&gt;$LOAD_BALANCER_NAME&lt;/span&gt;-ip --frontend-ip-name &lt;span class=&#34;nv&#34;&gt;$LOAD_BALANCER_NAME&lt;/span&gt;-front-end --backend-pool-name &lt;span class=&#34;nv&#34;&gt;$LOAD_BALANCER_NAME&lt;/span&gt;-back-end

&lt;span class=&#34;c1&#34;&gt;# create a load balancer probe on port 80
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;az network lb probe create -g &lt;span class=&#34;nv&#34;&gt;$RESOURCE_GROUP&lt;/span&gt; -n load-balancer-health-probe-80 --lb-name &lt;span class=&#34;nv&#34;&gt;$LOAD_BALANCER_NAME&lt;/span&gt; --protocol tcp --port &lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# create a load balancer traffic rule for port 80
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;az network lb rule create -g &lt;span class=&#34;nv&#34;&gt;$RESOURCE_GROUP&lt;/span&gt; -n load-balancer-traffic-rule-80 --lb-name &lt;span class=&#34;nv&#34;&gt;$LOAD_BALANCER_NAME&lt;/span&gt; --protocol tcp --frontend-port &lt;span class=&#34;m&#34;&gt;80&lt;/span&gt; --backend-port &lt;span class=&#34;m&#34;&gt;80&lt;/span&gt; --frontend-ip-name &lt;span class=&#34;nv&#34;&gt;$LOAD_BALANCER_NAME&lt;/span&gt;-front-end  --backend-pool-name &lt;span class=&#34;nv&#34;&gt;$LOAD_BALANCER_NAME&lt;/span&gt;-back-end --probe-name load-balancer-health-probe-80

&lt;span class=&#34;c1&#34;&gt;# create three NAT rules for port 22 (so we can ssh to each of the three nodes via the load balancer&amp;#39;s public ip address)
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;seq &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
  az network lb inbound-nat-rule create -g &lt;span class=&#34;nv&#34;&gt;$RESOURCE_GROUP&lt;/span&gt; -n nat-rule-for-node-&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt;-ssh --lb-name &lt;span class=&#34;nv&#34;&gt;$LOAD_BALANCER_NAME&lt;/span&gt; --protocol tcp --frontend-port &lt;span class=&#34;m&#34;&gt;422&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; --backend-port &lt;span class=&#34;m&#34;&gt;22&lt;/span&gt; --frontend-ip-name &lt;span class=&#34;nv&#34;&gt;$LOAD_BALANCER_NAME&lt;/span&gt;-front-end
&lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# allow port 22 (ssh) traffic into the network
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;az network nsg rule create -g &lt;span class=&#34;nv&#34;&gt;$RESOURCE_GROUP&lt;/span&gt; -n allow-ssh --nsg-name &lt;span class=&#34;nv&#34;&gt;$NSG_NAME&lt;/span&gt; --destination-port-ranges &lt;span class=&#34;m&#34;&gt;22&lt;/span&gt; --access Allow --description &lt;span class=&#34;s2&#34;&gt;&amp;#34;Allow inbound ssh traffic&amp;#34;&lt;/span&gt; --priority &lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# allow port 80 (http) traffic into the network
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;az network nsg rule create -g &lt;span class=&#34;nv&#34;&gt;$RESOURCE_GROUP&lt;/span&gt; -n allow-http --nsg-name &lt;span class=&#34;nv&#34;&gt;$NSG_NAME&lt;/span&gt; --destination-port-ranges &lt;span class=&#34;m&#34;&gt;80&lt;/span&gt; --access Allow --description &lt;span class=&#34;s2&#34;&gt;&amp;#34;Allow inbound http traffic&amp;#34;&lt;/span&gt; --priority &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# create three virtual network cards and associate with the network security group and load balancer. bind each NIC to one of the ssh nat rules we created
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;seq &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
  az network nic create -g &lt;span class=&#34;nv&#34;&gt;$RESOURCE_GROUP&lt;/span&gt; -n node-&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt;-private-nic --vnet-name &lt;span class=&#34;nv&#34;&gt;$VNET_NAME&lt;/span&gt; --subnet &lt;span class=&#34;nv&#34;&gt;$SUBNET_NAME&lt;/span&gt; --lb-name &lt;span class=&#34;nv&#34;&gt;$LOAD_BALANCER_NAME&lt;/span&gt; --lb-address-pools &lt;span class=&#34;nv&#34;&gt;$LOAD_BALANCER_NAME&lt;/span&gt;-back-end --lb-inbound-nat-rules nat-rule-for-node-&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt;-ssh
&lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# create an availability set with 3 fault domains and 3 update domains
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;az vm availability-set create -g &lt;span class=&#34;nv&#34;&gt;$RESOURCE_GROUP&lt;/span&gt; -n &lt;span class=&#34;nv&#34;&gt;$AVAILABILITY_SET_NAME&lt;/span&gt; --platform-fault-domain-count &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt; --platform-update-domain-count &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# generate ssh keys
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;ssh-keygen -t rsa -f ~/.ssh/docker_rsa -N &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# create three virtual machines
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;seq &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
  az vm create -g &lt;span class=&#34;nv&#34;&gt;$RESOURCE_GROUP&lt;/span&gt; -n node-&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; --ssh-key-value &lt;span class=&#34;s2&#34;&gt;&amp;#34;~/.ssh/docker_rsa.pub&amp;#34;&lt;/span&gt; --nics node-&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt;-private-nic --image &lt;span class=&#34;nv&#34;&gt;$OS_IMAGE&lt;/span&gt; --size &lt;span class=&#34;nv&#34;&gt;$VM_SIZE&lt;/span&gt; --authentication-type ssh --admin-username &lt;span class=&#34;nv&#34;&gt;$ADMIN_USERNAME&lt;/span&gt; --availability-set &lt;span class=&#34;nv&#34;&gt;$AVAILABILITY_SET_NAME&lt;/span&gt; --os-disk-name node-&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt;-os-disk
&lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;create-a-resource-group&#34;&gt;Create a resource group&lt;/h2&gt;

&lt;p&gt;In order to be able to easily organize and later remove any and all resources that are related to the docker swarm cluster I put everything in a resource group. Resource groups are bound to geographic locations so I created one that is close to my location. The location could be &lt;a href=&#34;https://azure.microsoft.com/en-us/regions/&#34;&gt;anywhere that Azure supports&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;create-a-network-security-group&#34;&gt;Create a network security group&lt;/h2&gt;

&lt;p&gt;We want to protect our network traffic with a firewall so we create a new network security group next. We need the network security group to exist before we create our virtual network and subnet so that we can associate the subnet to the network security group. That way, any rules that we create in the firewall will apply to everything connected to the subnet. This way we don&amp;rsquo;t have to manage rules for each individual NIC that gets attached to the subnet but instead we can manage the subnet as a whole.&lt;/p&gt;

&lt;h2 id=&#34;create-a-virtual-network&#34;&gt;Create a virtual network&lt;/h2&gt;

&lt;p&gt;We start off by creating a network that each of the swarm nodes will connect to. We also create a subnet within the network to isolate traffic between the nodes.&lt;/p&gt;

&lt;h2 id=&#34;create-a-subnet&#34;&gt;Create a subnet&lt;/h2&gt;

&lt;p&gt;We create a subnet within the virtual network and associate it to the network security group that we created previously. Any rules that we create later on for the firewall will apply to everything in this subnet.&lt;/p&gt;

&lt;h2 id=&#34;create-a-public-ip-address-for-the-load-balancer-front-end&#34;&gt;Create a public ip address for the load balancer (front-end)&lt;/h2&gt;

&lt;p&gt;Now that we have a network setup we&amp;rsquo;ll start creating a load balancer that will balance traffic between each node in the swarm cluster. There will only be one public ip to the swarm cluster and that will be the ip address of the load balancer.&lt;/p&gt;

&lt;h2 id=&#34;create-a-load-balancer&#34;&gt;Create a load balancer&lt;/h2&gt;

&lt;p&gt;Next we create a load balancer and associate it with the public ip address that we just created. The load balancer has a front-end ip and a back-end ip address pool that it balances traffic between.&lt;/p&gt;

&lt;h2 id=&#34;create-a-load-balancer-probe-on-port-80&#34;&gt;Create a load balancer probe on port 80&lt;/h2&gt;

&lt;p&gt;The load balancer has to have a way to detect if the nodes are healthy that it sends traffic to. We create a probe that will connect with each node using tcp port 80 traffic. If the node responds then the load balancer knows that the node is ready to receive traffic.&lt;/p&gt;

&lt;h2 id=&#34;create-a-load-balancer-traffic-rule-for-port-80&#34;&gt;Create a load balancer traffic rule for port 80&lt;/h2&gt;

&lt;p&gt;With the health probe in place, next we setup a traffic rule in the load balancer to forward tcp port 80 traffic to the nodes that are in the back-end pool. We associate this traffic rule with the health probe that we created.&lt;/p&gt;

&lt;h2 id=&#34;create-three-nat-rules-for-port-22-so-we-can-ssh-to-each-of-the-three-nodes-via-the-load-balancer-s-public-ip-address&#34;&gt;Create three NAT rules for port 22 (so we can ssh to each of the three nodes via the load balancer&amp;rsquo;s public ip address)&lt;/h2&gt;

&lt;p&gt;To finish out the load balancer setup we need to create NAT rules that will allow us to reach each individual node in the cluster when we need to manage it via ssh. In order to do this, we setup rules that will route tcp port 4221, 4222 and 4223 traffic to port 22 (the ssh port) in the back-end pool. The key thing is that we name each NAT rule with a unique name that we will later use to bind to the NICs of the swarm nodes. This is what will allow us to ssh to port 4221, 4222 and 4223 and connect to node 1, node 2 and node 3 behind the load balancer.&lt;/p&gt;

&lt;h2 id=&#34;allow-port-22-ssh-traffic-into-the-network&#34;&gt;Allow port 22 (ssh) traffic into the network&lt;/h2&gt;

&lt;p&gt;In order to get tcp port 22 traffic into the network we have to allow for it in the firewall (network security group or NSG).&lt;/p&gt;

&lt;h2 id=&#34;allow-port-80-http-traffic-into-the-network&#34;&gt;Allow port 80 (http) traffic into the network&lt;/h2&gt;

&lt;p&gt;Just like port 22 ssh traffic above, we also have to let tcp port 80 traffic into the network.&lt;/p&gt;

&lt;h2 id=&#34;create-three-virtual-network-cards&#34;&gt;Create three virtual network cards&lt;/h2&gt;

&lt;p&gt;In order to connect the swarm nodes together we have to create a NIC for them and associate the NICs with the subnet that we previously setup. We give each NIC a unique name, we place it into the load balancer&amp;rsquo;s back-end pool and we also associate the NIC with the uniquely named inbound NAT rule that we setup in order to allow us to reach the node via the load balancer for ssh traffic.&lt;/p&gt;

&lt;h2 id=&#34;create-an-availability-set-with-3-fault-domains-and-3-update-domains&#34;&gt;Create an availability set with 3 fault domains and 3 update domains&lt;/h2&gt;

&lt;p&gt;The virtual machines that we setup as swarm nodes must all be in the same availability set in order for the load balancer to be able to route traffic to them. You can read more about availability sets &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/virtual-machines/linux/manage-availability?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json&#34;&gt;here&lt;/a&gt; but in essence, what an availability set does is gives you a way to ensure that not all of your vm nodes will be rebooted at the same time (update domains) and provisions them across different physical hardware (fault domains) in order to increase their availability and up-time. In a future post I&amp;rsquo;d like to explore using the new preview feature of &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/availability-zones/az-overview&#34;&gt;Availability Zones&lt;/a&gt; to further improve the fault tolerance of the swarm cluster.&lt;/p&gt;

&lt;h2 id=&#34;generate-ssh-keys&#34;&gt;Generate ssh keys&lt;/h2&gt;

&lt;p&gt;In order to manage the virtual machines we generate an ssh keypair so that each vm can be managed by the same ssh key for ease of administration.&lt;/p&gt;

&lt;h2 id=&#34;create-three-virtual-machines&#34;&gt;Create three virtual machines&lt;/h2&gt;

&lt;p&gt;Finally we can provision the virtual machines. For each VM we give it a unique name that aligns with the name of it&amp;rsquo;s NIC and OS disk. We place it in the availability set that we created and associate it with the public key of the ssh key pair that we generated previously.&lt;/p&gt;

&lt;h2 id=&#34;install-docker-on-all-three-nodes&#34;&gt;Install docker on all three nodes&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;On all three nodes&lt;/strong&gt; you have to install docker. Repeat these commands on each node via an ssh session.&lt;/p&gt;

&lt;h3 id=&#34;ssh-to-the-specific-node&#34;&gt;SSH to the specific node&lt;/h3&gt;

&lt;p&gt;In order to reach each individual node via the load balancer you have to ssh to the correct port based on how we setup the NAT rules earlier.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;c&#34;&gt;# node 1&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ssh&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-i&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;~/.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ssh&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;docker_rsa&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wshaddix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;@&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;balancer&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ip&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;address&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-p&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;4221&lt;/span&gt;

&lt;span class=&#34;c&#34;&gt;# node 2&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ssh&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-i&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;~/.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ssh&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;docker_rsa&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wshaddix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;@&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;balancer&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ip&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;address&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-p&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;4222&lt;/span&gt;

&lt;span class=&#34;c&#34;&gt;# node 3&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;ssh&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-i&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;~/.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ssh&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;docker_rsa&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wshaddix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;@&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;balancer&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ip&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;address&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-p&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;4223&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;setup-the-docker-apt-repository&#34;&gt;Setup the docker apt repository&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;sudo&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;apt-get&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;update&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;sudo&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;apt-get&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;\&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;apt-transport-https&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;\&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;ca-certificates&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;\&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;curl&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;\&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;software-properties-common&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;curl&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-fsSL&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;com&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linux&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ubuntu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gpg&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sudo&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;apt-key&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;add&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;-&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;sudo&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;add-apt&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;-repository&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;\&lt;/span&gt;
   &lt;span class=&#34;s2&#34;&gt;&amp;#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;$(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lsb_release&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-cs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt; \
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;   stable&amp;#34;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;install-docker-ce&#34;&gt;Install Docker CE&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;sudo&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;apt-get&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;update&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;sudo&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;apt-get&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;docker-ce&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;17&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;09&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;~&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ce&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;~&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ubuntu&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;verify-that-docker-is-working-correctly&#34;&gt;Verify that docker is working correctly&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;sudo&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;run&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;hello-world&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;manage-docker-as-a-non-root-user&#34;&gt;Manage docker as a non-root user&lt;/h3&gt;

&lt;p&gt;Right now anytime you interact with the docker cli you have to prefix the &lt;code&gt;docker&lt;/code&gt; command with &lt;code&gt;sudo&lt;/code&gt;. If you want
 to allow your user to run the docker cli as non-root you can create a docker group and add your user to it. Note that you&amp;rsquo;ll have to log out and back in for this change to take effect.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;sudo&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;usermod&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-aG&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$USER&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;configure-docker-to-start-on-boot&#34;&gt;Configure docker to start on boot&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;sudo&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;systemctl&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;enable&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;initialize-the-docker-swarm&#34;&gt;Initialize the docker swarm&lt;/h2&gt;

&lt;p&gt;Make sure you run the following command on the &lt;strong&gt;swarm manager node&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;swarm&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;init&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;-advertise-addr&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;4&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The output of the above command will tell you what you need to run on the worker1 and worker2 nodes to join to the cluster.&lt;/p&gt;

&lt;h2 id=&#34;add-the-worker-nodes-to-the-cluster&#34;&gt;Add the worker nodes to the cluster&lt;/h2&gt;

&lt;p&gt;On the worker nodes run the command (my example is below) indicated when you initialized the swarm cluster from the previous step.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;swarm&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;join&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;-token&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;your&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;swarm&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cluster&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;join&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;token&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;2377&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;verify-the-swarm-cluster-is-up&#34;&gt;Verify the swarm cluster is up&lt;/h2&gt;

&lt;p&gt;On the manager node run the following command to ensure that the swarm is running with three nodes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;node&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ls&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;cleaning-up&#34;&gt;Cleaning up&lt;/h2&gt;

&lt;p&gt;After you are done and ready to deprovision all of the resources that we&amp;rsquo;ve created so that you are not billed for them, you can simply delete the resource group.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;az&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;group&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;delete&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-n&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dev-docker-swarm-us-east&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;You also may want to delete your docker_rsa ssh keypair if you are going to re-run these steps in the future.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;rm&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;~/.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ssh&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;docker_rsa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;*&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;You may (or may not) also want to remove the three nodes from your &lt;code&gt;~/.ssh/known_hosts&lt;/code&gt; file&lt;/p&gt;

&lt;h2 id=&#34;saving-time&#34;&gt;Saving time&lt;/h2&gt;

&lt;p&gt;If you are creating and removing swarm clusters frequently it is faster to run all of the commands at once as opposed to copy/paste/running each one. I&amp;rsquo;ve setup gists to speed up the process.&lt;/p&gt;

&lt;h3 id=&#34;create-the-entire-three-node-swarm-cluster-on-azure&#34;&gt;Create the entire three node swarm cluster on Azure&lt;/h3&gt;

&lt;p&gt;After you&amp;rsquo;ve logged into your Azure account you can run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;wget&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-O&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;githubusercontent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;com&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wshaddix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;3acf084908f31d7c18f1f20f53b19147&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;raw&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bf4ea5aa97a92020be50cd1c0cc2f7c7a6b65fbc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Setting&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;2520up&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;2520docker&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;2520swarm&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;2520on&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;2520azure&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bash&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This will setup the three virtual machines.&lt;/p&gt;

&lt;h3 id=&#34;install-docker&#34;&gt;Install Docker&lt;/h3&gt;

&lt;p&gt;Next, you can ssh into each of the three nodes and run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;wget&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-O&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;githubusercontent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;com&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wshaddix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;91058d471c525050f005e98eda85e3d3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;raw&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;46de5d48bd4c4e51a9701e743c85fbf4dc3a3ce4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Install&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;2520Docker&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;2520on&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;2520Ubuntu&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;252017&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;04&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bash&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;initialize-swarm-mode&#34;&gt;Initialize swarm mode&lt;/h3&gt;

&lt;p&gt;Now you&amp;rsquo;ve got your virtual machines provisioned and docker installed you can just run the commands listed above to initialize the swarm and join the worker nodes.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Logging and Monitoring on a Docker Swarm Cluster</title>
      <link>http://www.wesshaddix.com/post/logging-and-monitoring-on-a-docker-swarm-cluster/</link>
      <pubDate>Tue, 12 Dec 2017 19:11:04 -0500</pubDate>
      
      <guid>http://www.wesshaddix.com/post/logging-and-monitoring-on-a-docker-swarm-cluster/</guid>
      
        <description>&lt;p&gt;How to setup data analytics, metrics and events collection and logging on a docker swarm cluster using sematext SPM and Logsene.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;

&lt;p&gt;After &lt;a href=&#34;http://www.wesshaddix.com/post/three-node-docker-swarm-cluster/&#34;&gt;setting up a docker swarm cluster&lt;/a&gt; and then being able to &lt;a href=&#34;http://www.wesshaddix.com/post/visualizing-a-docker-swarm-cluster/&#34;&gt;visualize what is running on the cluster&lt;/a&gt; the next concept I wanted to implement was logging and metrics. I&amp;rsquo;ve used several 3rd party logging and metrics services in the past but while reading &lt;a href=&#34;https://www.amazon.com/Docker-Management-Design-Patterns-Services/dp/148422972X&#34;&gt;Docker Management Design Patterns&lt;/a&gt; I found a great all-in-one solution called &lt;a href=&#34;https://sematext.com/&#34;&gt;Sematext&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;They have a service that includes logging, metrics, events and alerts and they have a docker agent that gets everything going pretty quickly. You simply sign up for an account, create your application and use your application tokens to configure your docker agent within your swarm cluster. The agent runs on each node of the swarm cluster.&lt;/p&gt;

&lt;h2 id=&#34;create-your-sematext-account&#34;&gt;Create your Sematext account&lt;/h2&gt;

&lt;p&gt;The first step is to head over to &lt;a href=&#34;https://apps.sematext.com/ui/registration&#34;&gt;Sematext&amp;rsquo;s registration page&lt;/a&gt; and create yourself an account.&lt;/p&gt;

&lt;h2 id=&#34;create-your-application&#34;&gt;Create your application&lt;/h2&gt;

&lt;p&gt;Next head over to the &lt;a href=&#34;https://apps.sematext.com/ui/integrations/create/docker&#34;&gt;docker integration page&lt;/a&gt; and create a new application for the cluster. Be sure to also include logging support (checked by default)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.wesshaddix.com/img/sematext-new-app.png&#34; alt=&#34;screenshot&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;configure-your-swarm-stack&#34;&gt;Configure your swarm stack&lt;/h2&gt;

&lt;p&gt;To make things easy to configure and deploy I created a &lt;a href=&#34;https://github.com/wshaddix/docker-swarm-config&#34;&gt;GitHub repo&lt;/a&gt; that stores my stack definition. So far I&amp;rsquo;ve included the vizualizer and the sematext docker agent as one stack as shown below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;version&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;3.4&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;services&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;vizualizer&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;image&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;dockersamples/visualizer&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;volumes&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;type&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;bind&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;source&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/var/run/docker.sock&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;target&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/var/run/docker.sock&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;ports&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;8080:8080/tcp&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;deploy&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;replicas&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;placement&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;constraints&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;node.role&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;==&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;manager&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;sematext&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;image&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;sematext/sematext-agent-docker&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;volumes&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;type&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;bind&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;source&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/var/run/docker.sock&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;target&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/var/run/docker.sock&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;type&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;bind&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;source&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;target&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/rootfs&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;type&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;bind&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;source&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/etc/localtime&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;target&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/etc/localtime&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;deploy&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;mode&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;global&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;environment&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;SPM_TOKEN=&amp;lt;YOUR&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;SPM&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;TOKEN&lt;span class=&#34;sd&#34;&gt;&amp;gt;
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;      - LOGSENE_TOKEN=&amp;lt;YOUR LOGSENE TOKEN&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;I know that the SPM_TOKEN and LOGSENE_TOKEN shouldn&amp;rsquo;t be in a git repo. I&amp;rsquo;ll address that later, this is for learning/demo purposes only :)&lt;/p&gt;

&lt;h2 id=&#34;setting-up-your-swarm-stack&#34;&gt;Setting up your swarm stack&lt;/h2&gt;

&lt;p&gt;In order to deploy your swarm stack you can:&lt;/p&gt;

&lt;h3 id=&#34;ssh-into-your-swarm-manager-node&#34;&gt;ssh into your swarm manager node&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;ssh&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-i&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Users&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wessh&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;\.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ssh&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;docker_rsa&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wshaddix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;@&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mgr&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ip&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;address&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;checkout-your-swarm-configuration-repo&#34;&gt;Checkout your swarm configuration repo&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;git&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;clone&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;your&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;git&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;repo&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;address&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;cd&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;your&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;repo&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;deploy-your-swarm-stack&#34;&gt;Deploy your swarm stack&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;n&#34;&gt;docker&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stack&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;deploy&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-c&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;swarm-services&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;yaml&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;monitoring&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;view-metrics-and-logs&#34;&gt;View metrics and logs&lt;/h2&gt;

&lt;p&gt;This is going to run the Sematext docker agent on each of the host nodes in the cluster. Once they start reporting back to Sematext you can view the results in the Sematext web ui.&lt;/p&gt;

&lt;h3 id=&#34;metrics&#34;&gt;Metrics&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://www.wesshaddix.com/img/sematext-metrics.png&#34; alt=&#34;metrics&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;logs&#34;&gt;Logs&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://www.wesshaddix.com/img/sematext-logs.png&#34; alt=&#34;logs&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Showing UTF8 Characters in TeamCity 10 Build Logs</title>
      <link>http://www.wesshaddix.com/post/team-city-utf-8/</link>
      <pubDate>Tue, 15 Aug 2017 21:43:19 -0400</pubDate>
      
      <guid>http://www.wesshaddix.com/post/team-city-utf-8/</guid>
      
        <description>&lt;p&gt;As part of a continuous integration pipeline I&amp;rsquo;m running my Postman api tests after every deployment to our development environment via TeamCity and Newman. One issue that I encountered was that the TeamCity agent build log wasn&amp;rsquo;t showing formatted newman output correctly because by default it doesn&amp;rsquo;t show UTF8. In order to fix this you just have to update your &lt;code&gt;C:\TeamCity\buildAgent\conf\buildAgent.properties&lt;/code&gt; file to include&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Bash&#34; data-lang=&#34;Bash&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Bash&#34; data-lang=&#34;Bash&#34;&gt;teamcity.runner.commandline.stdstreams.encoding&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;UTF-8&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;and then restart the TeamCity Agent service. The next time newman runs, you&amp;rsquo;ll be able to decipher your build log.&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>